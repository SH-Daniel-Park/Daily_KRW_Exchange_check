
import io
import os
import re
from datetime import date, timedelta, datetime

import requests
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

# ================= App Config =================
st.set_page_config(page_title="KRW í™˜ìœ¨ ë¹„êµ (ECOS vs ì€í–‰)", page_icon="ğŸ’±", layout="wide", initial_sidebar_state="expanded")
APP_TITLE = "ğŸ’± í•´ì™¸í†µí™” ëŒ€ë¹„ ì›í™” í™˜ìœ¨ ë¹„êµ (ECOS vs ì€í–‰ ê³ ì‹œ)"

# ECOS: 3.1.1.1. ì£¼ìš”êµ­ í†µí™”ì˜ ëŒ€ì›í™”í™˜ìœ¨ (ì£¼ê¸° D)
ECOS_TABLE_CODE = "731Y001"
MAX_ROWS = 100000

CURRENCIES = {
    "USD": "ë¯¸êµ­ ë‹¬ëŸ¬ (USD)",
    "EUR": "ìœ ë¡œ (EUR)",
    "JPY": "ì¼ë³¸ ì—” (JPY)",
    "CNY": "ì¤‘êµ­ ìœ„ì•ˆ (CNY)",
    "GBP": "ì˜êµ­ íŒŒìš´ë“œ (GBP)",
    "AUD": "í˜¸ì£¼ ë‹¬ëŸ¬ (AUD)",
    "CAD": "ìºë‚˜ë‹¤ ë‹¬ëŸ¬ (CAD)",
    "CHF": "ìŠ¤ìœ„ìŠ¤ í”„ë‘ (CHF)",
    "HKD": "í™ì½© ë‹¬ëŸ¬ (HKD)",
    "SGD": "ì‹±ê°€í¬ë¥´ ë‹¬ëŸ¬ (SGD)",
    "NZD": "ë‰´ì§ˆëœë“œ ë‹¬ëŸ¬ (NZD)",
}

# JPYëŠ” 100ì—” ê¸°ì¤€ ì œê³µ â†’ 1ì—”ìœ¼ë¡œ í™˜ì‚°
PER_UNIT_DEFAULT = {"JPY": 100}

SOURCE_OPTIONS = ["ECOS", "ì€í–‰ TTM(ë§¤ë§¤ê¸°ì¤€)", "ì€í–‰ TTS(íŒ” ë•Œ)", "ì€í–‰ TTB(ì‚´ ë•Œ)"]

# ================= ECOS helpers =================
def get_ecos_key() -> str:
    # 1) Streamlit Cloud secrets
    try:
        k = st.secrets.get("ECOS_API_KEY", "")
        if k:
            return k
    except Exception:
        pass
    # 2) Env var
    k = os.getenv("ECOS_API_KEY", "")
    if k:
        return k
    # 3) Hardcoded (local test only; do NOT commit real keys)
    return "YOUR_ECOS_API_KEY"

def ecos_get_item_list(diag=None) -> list[dict]:
    key = get_ecos_key()
    url = f"https://ecos.bok.or.kr/api/StatisticItemList/{key}/json/kr/1/{MAX_ROWS}/{ECOS_TABLE_CODE}/"
    if diag is not None:
        diag.append(f"ECOS ItemList: {url}")
    r = requests.get(url, timeout=30)
    r.raise_for_status()
    data = r.json()
    block = data.get("StatisticItemList")
    if not block or "row" not in block:
        result = data.get("RESULT", {})
        code = (result or {}).get("CODE", "UNKNOWN")
        msg  = (result or {}).get("MESSAGE", "ECOS API ì‘ë‹µ ì˜¤ë¥˜")
        raise ValueError(f"ECOS API ì˜¤ë¥˜: {code} {msg}")
    rows = block.get("row") or []
    if not rows:
        raise ValueError("í†µí™” í•­ëª© ëª©ë¡ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    return rows

def _collect_names(row: dict) -> str:
    names = []
    for k in ["ITEM_NAME", "ITEM_NAME1", "ITEM_NAME2", "ITEM_NAME3", "ITEM_NAME4"]:
        v = str(row.get(k, "")).strip()
        if v:
            names.append(v)
    return " | ".join(names)

def ecos_resolve_item_codes(diag=None) -> dict:
    rows = ecos_get_item_list(diag=diag)
    comp = {}

    def which_currency(label: str) -> str | None:
        L = label.lower()
        if ("ë¯¸êµ­" in L and "ë‹¬ëŸ¬" in L) or "usd" in L: return "USD"
        if ("ìœ ë¡œ" in L) or "eur" in L: return "EUR"
        if ("ì¼ë³¸" in L and "ì—”" in L) or "jpy" in L: return "JPY"
        if ("ì¤‘êµ­" in L and "ìœ„ì•ˆ" in L) or "cny" in L: return "CNY"
        if ("ì˜êµ­" in L and "íŒŒìš´ë“œ" in L) or "gbp" in L: return "GBP"
        if ("í˜¸ì£¼" in L and "ë‹¬ëŸ¬" in L) or "aud" in L: return "AUD"
        if ("ìºë‚˜ë‹¤" in L and "ë‹¬ëŸ¬" in L) or "cad" in L: return "CAD"
        if ("ìŠ¤ìœ„ìŠ¤" in L and "í”„ë‘" in L) or "chf" in L: return "CHF"
        if ("í™ì½©" in L and "ë‹¬ëŸ¬" in L) or "hkd" in L: return "HKD"
        if ("ì‹±ê°€í¬ë¥´" in L and "ë‹¬ëŸ¬" in L) or "sgd" in L: return "SGD"
        if ("ë‰´ì§ˆëœë“œ" in L and "ë‹¬ëŸ¬" in L) or "nzd" in L: return "NZD"
        return None

    samples = []
    for row in rows:
        code = str(row.get("ITEM_CODE1", "") or row.get("ITEM_CODE", "")).strip()
        label = _collect_names(row)
        if len(samples) < 12:
            samples.append(f"{code} :: {label}")
        if not code or not label:
            continue
        cur = which_currency(label)
        if cur and cur not in comp:
            comp[cur] = code

    if diag is not None:
        diag.append(f"Resolved item codes: {comp}")
        if not comp:
            diag.append("ItemList ì˜ˆì‹œ(ìµœëŒ€ 12):")
            for s in samples:
                diag.append(f"  - {s}")
    return comp

def ecos_timeseries(item_code: str, start_yyyymmdd: str, end_yyyymmdd: str, diag=None) -> pd.DataFrame:
    key = get_ecos_key()
    url = (
        f"https://ecos.bok.or.kr/api/StatisticSearch/{key}/json/kr/1/{MAX_ROWS}/"
        f"{ECOS_TABLE_CODE}/D/{start_yyyymmdd}/{end_yyyymmdd}/{item_code}/?/?/?/"
    )
    if diag is not None:
        diag.append(f"ECOS Search: {url}")
    r = requests.get(url, timeout=30)
    r.raise_for_status()
    data = r.json()
    block = data.get("StatisticSearch")
    if not block or "row" not in block:
        result = data.get("RESULT", {})
        code = (result or {}).get("CODE", "UNKNOWN")
        msg  = (result or {}).get("MESSAGE", "ECOS API ì‘ë‹µ ì˜¤ë¥˜")
        raise ValueError(f"ECOS API ì˜¤ë¥˜: {code} {msg}")
    rows = block.get("row") or []
    if not rows:
        raise ValueError("ìš”ì²­ êµ¬ê°„ ë°ì´í„° ì—†ìŒ (INFO-200)")
    recs = []
    for obj in rows:
        t = str(obj.get("TIME","")).strip()
        v = str(obj.get("DATA_VALUE","")).strip()
        if not t or not v:
            continue
        dt = pd.to_datetime(t, errors="coerce")
        if pd.isna(dt):
            continue
        try:
            val = float(v.replace(",",""))
        except Exception:
            continue
        recs.append({"date": dt, "value": val})
    if not recs:
        raise ValueError("êµ¬ë¬¸ì€ ì •ìƒì´ë‚˜ ë³€í™˜ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    df = pd.DataFrame(recs).sort_values("date").set_index("date")
    return df

def fetch_ecos_series(currency: str, start_date: date, end_date: date, diag=None) -> pd.DataFrame:
    mapping = ecos_resolve_item_codes(diag=diag)
    item_code = mapping.get(currency)
    if not item_code:
        raise ValueError(f"{currency}ì˜ ì•„ì´í…œì½”ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ECOS {ECOS_TABLE_CODE})")
    s = start_date.strftime("%Y%m%d")
    e = end_date.strftime("%Y%m%d")
    raw = ecos_timeseries(item_code, s, e, diag=diag)
    rng = pd.date_range(start=start_date, end=end_date, freq="D")
    df = raw.reindex(rng).ffill()
    df.index.name = "date"
    per_unit = PER_UNIT_DEFAULT.get(currency, 1)
    df["value"] = df["value"] / (per_unit or 1)
    df.rename(columns={"value": "ECOS"}, inplace=True)
    return df

# ================= Bank CSV helpers =================
def _norm(s: str) -> str:
    return re.sub(r"[^a-z0-9ê°€-í£]", "", s.lower())

def _guess_date_col(cols):
    for c in cols:
        n = _norm(str(c))
        if any(k in n for k in ["date","ë‚ ì§œ","ì¼ì","ê¸°ì¤€ì¼"]):
            return c
    return cols[0]

def _guess_value_col(cols, kind: str):
    kind = kind.lower()
    for c in cols:
        n = _norm(str(c))
        if kind == "ttm" and ("ttm" in n or "ê¸°ì¤€" in n or "ë§¤ë§¤ê¸°ì¤€" in n):
            return c
        if kind == "tts" and ("tts" in n or "íŒ”ë•Œ" in n or "ë³´ë‚¼ë•Œ" in n or "ë§¤ë„" in n):
            return c
        if kind == "ttb" and ("ttb" in n or "ì‚´ë•Œ" in n or "ë°›ì„ë•Œ" in n or "ë§¤ì…" in n):
            return c
    return None

def read_bank_csv(file_bytes: bytes, encoding_try=("utf-8","cp949")) -> pd.DataFrame:
    last_err = None
    for enc in encoding_try:
        try:
            return pd.read_csv(io.BytesIO(file_bytes), encoding=enc)
        except Exception as e:
            last_err = e
    raise last_err

def normalize_bank_df(df: pd.DataFrame, date_col, ttm_col, tts_col, ttb_col, unit_divisor: int) -> pd.DataFrame:
    out = pd.DataFrame()
    d = pd.to_datetime(df[date_col], errors="coerce")
    out["date"] = d
    out = out.dropna(subset=["date"]).set_index("date").sort_index()

    def to_num(s):
        try:
            return float(str(s).replace(",","").strip())
        except Exception:
            return None

    if ttm_col:
        out["ì€í–‰ TTM(ë§¤ë§¤ê¸°ì¤€)"] = df[ttm_col].map(to_num) / (unit_divisor or 1)
    if tts_col:
        out["ì€í–‰ TTS(íŒ” ë•Œ)"] = df[tts_col].map(to_num) / (unit_divisor or 1)
    if ttb_col:
        out["ì€í–‰ TTB(ì‚´ ë•Œ)"] = df[ttb_col].map(to_num) / (unit_divisor or 1)
    out = out.dropna(how="all")
    return out

def last_available_from_series(series: pd.Series, end_ts: pd.Timestamp):
    if series.empty:
        return None, None
    idx = series.index[series.index <= end_ts]
    if len(idx)==0:
        return series.index.min(), float(series.iloc[0])
    last_idx = idx.max()
    return last_idx, float(series.loc[last_idx])

# ================= UI =================
st.title(APP_TITLE)
st.caption("ì†ŒìŠ¤: í•œêµ­ì€í–‰ ECOS(731Y001, ì¼ë³„) + ì€í–‰ ê³ ì‹œ(TTM/TTS/TTB, CSV ì—…ë¡œë“œ). "
           "JPYëŠ” ì€í–‰/ECOS ëª¨ë‘ 100ì—” ë‹¨ìœ„ì¼ ìˆ˜ ìˆì–´ ë‹¨ìœ„ë¥¼ ë§ì¶° ë¹„êµí•©ë‹ˆë‹¤.")

with st.sidebar:
    st.header("ì„¤ì • / ì…ë ¥")
    cur = st.selectbox("í†µí™” ì„ íƒ", options=list(CURRENCIES.keys()), format_func=lambda k: CURRENCIES[k])
    today = date.today()
    start_default = today - timedelta(days=90)
    start_dt = st.date_input("ì‹œì‘ì¼", start_default, max_value=today)
    end_dt = st.date_input("ì¢…ë£Œì¼", today, min_value=start_dt, max_value=today)

    sources = st.multiselect("ì†ŒìŠ¤ ì„ íƒ(ë¹„êµì„ )", options=["ECOS","ì€í–‰ TTM(ë§¤ë§¤ê¸°ì¤€)","ì€í–‰ TTS(íŒ” ë•Œ)","ì€í–‰ TTB(ì‚´ ë•Œ)"], default=["ECOS"])

    st.markdown("**ì€í–‰ ê³ ì‹œ í™˜ìœ¨ CSV ì—…ë¡œë“œ (ì„ íƒ)**")
    bank_file = st.file_uploader("CSV íŒŒì¼ ì„ íƒ", type=["csv"], help="ì—´ ì˜ˆì‹œ: Date, TTM(ë§¤ë§¤ê¸°ì¤€), TTS(íŒ” ë•Œ), TTB(ì‚´ ë•Œ)")

    bank_unit_default = 100 if cur == "JPY" else 1
    bank_unit = st.radio("ì€í–‰ ë°ì´í„° ë‹¨ìœ„", options=[1,100], index=(1 if bank_unit_default==100 else 0),
                         help="ì€í–‰ CSVê°€ 100JPY ë‹¨ìœ„ë©´ 100ì„ ì„ íƒí•˜ì„¸ìš”. (ë‹¤ë¥¸ í†µí™”ëŠ” ë³´í†µ 1)")

    ttm_col = tts_col = ttb_col = date_col = None
    bank_df_raw = None
    if bank_file is not None:
        try:
            bank_df_raw = read_bank_csv(bank_file.getvalue())
            cols = list(bank_df_raw.columns)
            date_col_guess = _guess_date_col(cols)
            ttm_guess = _guess_value_col(cols, "ttm")
            tts_guess = _guess_value_col(cols, "tts")
            ttb_guess = _guess_value_col(cols, "ttb")
            st.write("CSV ì—´ ë§¤í•‘:")
            date_col = st.selectbox("ë‚ ì§œ ì—´", options=cols, index=cols.index(date_col_guess) if date_col_guess in cols else 0)
            ttm_col = st.selectbox("TTM(ë§¤ë§¤ê¸°ì¤€) ì—´", options=["(ì—†ìŒ)"] + cols,
                                   index=(["(ì—†ìŒ)"]+cols).index(ttm_guess) if ttm_guess in (cols) else 0)
            tts_col = st.selectbox("TTS(íŒ” ë•Œ) ì—´", options=["(ì—†ìŒ)"] + cols,
                                   index=(["(ì—†ìŒ)"]+cols).index(tts_guess) if tts_guess in (cols) else 0)
            ttb_col = st.selectbox("TTB(ì‚´ ë•Œ) ì—´", options=["(ì—†ìŒ)"] + cols,
                                   index=(["(ì—†ìŒ)"]+cols).index(ttb_guess) if ttb_guess in (cols) else 0)
            ttm_col = None if ttm_col == "(ì—†ìŒ)" else ttm_col
            tts_col = None if tts_col == "(ì—†ìŒ)" else tts_col
            ttb_col = None if ttb_col == "(ì—†ìŒ)" else ttb_col
        except Exception as e:
            st.error(f"CSV ì½ê¸° ì‹¤íŒ¨: {e}")

    run = st.button("ê·¸ë˜í”„ ê·¸ë¦¬ê¸°", type="primary")

st.markdown("---")
with st.expander("ì€í–‰ ê³ ì‹œ í™˜ìœ¨ ê°€ì ¸ì˜¤ëŠ” ë°©ë²•(ì•ˆë‚´)", expanded=False):
    st.markdown(
        """
- **ì›¹ í˜ì´ì§€ì—ì„œ ë³µì‚¬/CSV ì €ì¥**: í•˜ë‚˜ì€í–‰/ë‹¤ë¥¸ ì‹œì¤‘ì€í–‰ì˜ í™˜ìœ¨ í‘œì—ì„œ ë‚ ì§œÂ·TTM/TTS/TTBë¥¼ ë‚´ë ¤ë°›ì•„ CSVë¡œ ì €ì¥í•´ ì—…ë¡œë“œí•˜ì„¸ìš”.
- **ì§ì ‘ CSV ì‘ì„±**: ì•„ë˜ **í…œí”Œë¦¿ CSV**ë¥¼ ë‚´ë ¤ë°›ì•„ ë‚ ì§œì™€ ê°’ì„ ì±„ì›Œ ì—…ë¡œë“œí•˜ì„¸ìš”.
- **ë‹¨ìœ„ ë§ì¶”ê¸°**: JPYëŠ” ì€í–‰/ECOSê°€ 100ì—” ë‹¨ìœ„ë¥¼ ì“°ê¸°ë„ í•˜ë¯€ë¡œ, ì‚¬ì´ë“œë°” **ì€í–‰ ë°ì´í„° ë‹¨ìœ„**ì—ì„œ 1 ë˜ëŠ” 100ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.
- **ì—´ ì´ë¦„ì€ ììœ **ì…ë‹ˆë‹¤. ì—…ë¡œë“œ í›„ì— ì•±ì—ì„œ **ë‚ ì§œ/TTM/TTS/TTB ì—´ì„ ì§ì ‘ ë§¤í•‘**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
    )
    tmpl_rng = pd.date_range(start=date.today()-timedelta(days=30), end=date.today(), freq="D")
    tmpl = pd.DataFrame({"Date": tmpl_rng.strftime("%Y-%m-%d"), "TTM": "", "TTS": "", "TTB": ""})
    buf = io.StringIO()
    tmpl.to_csv(buf, index=False)
    st.download_button("ì€í–‰ í™˜ìœ¨ í…œí”Œë¦¿ CSV ë‹¤ìš´ë¡œë“œ", data=buf.getvalue().encode("utf-8"),
                       file_name=f"bank_fx_template.csv", mime="text/csv")

# ================= Run =================
if run:
    diag = []
    series_frames = []

    try:
        # ECOS
        if "ECOS" in sources:
            ecos_df = fetch_ecos_series(cur, start_dt, end_dt, diag=diag)
            series_frames.append(ecos_df[["ECOS"]])

        # Bank CSV
        if any(s in sources for s in ["ì€í–‰ TTM(ë§¤ë§¤ê¸°ì¤€)", "ì€í–‰ TTS(íŒ” ë•Œ)", "ì€í–‰ TTB(ì‚´ ë•Œ)"]):
            if bank_df_raw is None:
                st.warning("ì€í–‰ ì†ŒìŠ¤ë¥¼ ì„ íƒí–ˆì§€ë§Œ CSVê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í…œí”Œë¦¿ìœ¼ë¡œ ì‘ì„±í•˜ê±°ë‚˜ ì›¹ì—ì„œ ì €ì¥í•œ CSVë¥¼ ì˜¬ë ¤ì£¼ì„¸ìš”.")
            else:
                bank_norm = normalize_bank_df(bank_df_raw, date_col, ttm_col, tts_col, ttb_col, unit_divisor=bank_unit)
                rng = pd.date_range(start=start_dt, end=end_dt, freq="D")
                bank_norm = bank_norm.reindex(rng).ffill()
                bank_norm.index.name = "date"
                keep_cols = [c for c in bank_norm.columns if c in sources]
                if keep_cols:
                    series_frames.append(bank_norm[keep_cols])

        if not series_frames:
            st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ECOS ë˜ëŠ” ì€í–‰ ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ê³ , CSVë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
            st.stop()

        all_df = pd.concat(series_frames, axis=1).dropna(how="all")
        if all_df.empty:
            st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„ì„ ì¡°ì •í•˜ê±°ë‚˜, CSV ë§¤í•‘/ë‹¨ìœ„ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
            st.stop()

        end_ts = pd.to_datetime(end_dt.isoformat())
        badges = []
        for col in all_df.columns:
            s = all_df[col].dropna()
            if s.empty: 
                continue
            idx = s.index[s.index <= end_ts]
            last_dt = idx.max() if len(idx)>0 else s.index.max()
            val = float(s.loc[last_dt])
            badges.append(f"<div style='margin:4px 8px;display:inline-block;padding:8px 10px;border-radius:10px;background:#f5f5f5'>{col}: {val:,.4f} KRW (ê¸°ì¤€ì¼ {last_dt.date().isoformat()})</div>")
        if badges:
            st.markdown("<div>" + " ".join(badges) + "</div>", unsafe_allow_html=True)

        st.subheader(f"ì¼ë³„ í™˜ìœ¨ ì¶”ì´ (KRW per 1 {cur}) â€” ì„ íƒ ì†ŒìŠ¤ ë¹„êµ")
        fig, ax = plt.subplots(figsize=(10, 4.8))
        for col in all_df.columns:
            ax.plot(all_df.index, all_df[col], label=col)
        ax.set_xlabel("ë‚ ì§œ")
        ax.set_ylabel(f"KRW per 1 {cur}")
        ax.grid(True, alpha=0.3)
        ax.legend()
        st.pyplot(fig, clear_figure=True)

        st.subheader("ë°ì´í„° í‘œ")
        disp = all_df.round(6)
        st.dataframe(disp)

        def to_csv_bytes(df: pd.DataFrame) -> bytes:
            sio = io.StringIO()
            df.to_csv(sio, encoding="utf-8")
            return sio.getvalue().encode("utf-8")
        def to_excel_bytes(df: pd.DataFrame, sheet_name: str = "FX") -> bytes:
            out = io.BytesIO()
            try:
                with pd.ExcelWriter(out, engine="xlsxwriter") as writer:
                    df.to_excel(writer, sheet_name=sheet_name)
            except Exception:
                out = io.BytesIO()
                with pd.ExcelWriter(out, engine="openpyxl") as writer:
                    df.to_excel(writer, sheet_name=sheet_name)
            out.seek(0)
            return out.read()

        c1, c2 = st.columns(2)
        with c1:
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", data=to_csv_bytes(disp),
                               file_name=f"fx_compare_{cur}_{start_dt.isoformat()}_{end_dt.isoformat()}.csv",
                               mime="text/csv")
        with c2:
            st.download_button("ì—‘ì…€(.xlsx) ë‹¤ìš´ë¡œë“œ", data=to_excel_bytes(disp),
                               file_name=f"fx_compare_{cur}_{start_dt.isoformat()}_{end_dt.isoformat()}.xlsx",
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        with st.expander("ì§„ë‹¨(ìš”ì²­ URL ë° ìƒíƒœ)"):
            for line in diag:
                st.code(line)

    except Exception as e:
        with st.expander("ì§„ë‹¨(ìš”ì²­ URL ë° ìƒíƒœ)"):
            for line in diag:
                st.code(line)
        st.error(f"ì˜¤ë¥˜: {e}")
